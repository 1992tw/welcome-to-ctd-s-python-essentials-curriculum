{
  "id": "68796c78a4ac7ef2a17a617c",
  "lessonNumber": 4,
  "title": "Lesson 4 — Intro to Data Engineering",
  "status": "pending",
  "assignment": {
    "title": "Assignment for Lesson 4",
    "objective": "No objective specified",
    "expectedCapabilities": [],
    "instructions": [],
    "tasks": [
      {
        "taskNumber": 1,
        "title": "Task 1",
        "description": "## Lesson 4 Assignment — Intro to Data Engineering\n### Data Analysis and Manipulation with Pandas\n\n### **Objective:**\nIn this assignment, you will explore the basic functionalities of the Pandas library in Python, including creating, manipulating, inspecting, and analyzing data using various DataFrame methods. The goal is to understand how to handle data efficiently and perform essential operations to inspect and analyze datasets.\n\n### **Step 1: Complete the Coding Tasks**  \n\nHomework for this assignment is created within your `python_homework` folder.  Create an `assignment4` branch and change to the `assignment4` folder.  Write your code in `assignment4.py`.  As with the previous lessons, you will run unit tests on the assignment `pytest -v -x assignment4-test.py`.\n\n---\n\n### **Tasks:**\n\n### **Task 1: Introduction to Pandas - Creating and Manipulating DataFrames**\n1. **Create a DataFrame from a dictionary:**\n   - Use a dictionary containing the following data:\n     - `Name`: ['Alice', 'Bob', 'Charlie']\n     - `Age`: [25, 30, 35]\n     - `City`: ['New York', 'Los Angeles', 'Chicago']\n   - Convert the dictionary into a DataFrame using Pandas.\n   - Print the DataFrame to verify its creation.\n   - save the DataFrame in a variable called `task1_data_frame` and run the tests.\n\n2. **Add a new column:**\n   - Make a copy of the dataFrame you created named `task1_with_salary` (use the `copy()` method)\n   - Add a column called `Salary` with values `[70000, 80000, 90000]`.\n   - Print the new DataFrame and run the tests.\n\n3. **Modify an existing column:**\n   - Make a copy of `task1_with_salary` in a variable named `task1_older`\n   - Increment the `Age` column by 1 for each entry.\n   - Print the modified DataFrame to verify the changes and run the tests.\n\n4. **Save the DataFrame as a CSV file:**\n   - Save the `task1_older` DataFrame to a file named `employees.csv` using ```to_csv()```, do not include an index in the csv file.\n   - Look at the contents of the CSV file to see how it's formatted.\n   - Run the tests.\n     \n\n### **Task 2: Loading Data from CSV and JSON**\n1. **Read data from a CSV file:**\n   - Load the CSV file from Task 1 into a new DataFrame saved to a variable `task2_employees`.\n   - Print it and run the tests to verify the contents.\n\n2. **Read data from a JSON file:**\n   - Create a JSON file (`additional_employees.json`).  The file adds two new employees.  Eve, who is 28, lives in Miami, and has a salary of 60000, and Frank, who is 40, lives in Seattle, and has a salary of 95000.\n   - Load this JSON file into a new DataFrame and assign it to the variable `json_employees`.\n   - Print the DataFrame to verify it loaded correctly and run the tests.\n\n3. **Combine DataFrames:**\n   - Combine the data from the JSON file into the DataFrame Loaded from the CSV file and save it in the variable `more_employees`.\n   - Print the combined Dataframe and run the tests.\n\n### **Task 3: Data Inspection - Using Head, Tail, and Info Methods**\n1. **Use the `head()` method:**\n   - Assign the first three rows of the `more_employees` DataFrame to the variable `first_three`\n   - Print the variable and run the tests.\n\n2. **Use the `tail()` method:**\n   - Assign the last two rows of the `more_employees` DataFrame to the variable `last_two`\n   - Print the variable and run the tests.\n\n3. **Get the `shape` of a DataFrame**\n   - Assign the shape of the `more_employees` DataFrame to the variable `employee_shape`\n   - Print the variable and run the tests \n\n4. **Use the `info()` method:**\n   - Print a concise summary of the DataFrame using the `info()` method to understand the data types and non-null counts.\n\n### **Task 4: Data Cleaning**\n\n1. Create a DataFrame from `dirty_data.csv` file and assign it to the variable `dirty_data`.\n   - Print it and run the tests.\n   - Create a copy of the dirty data in the varialble `clean_data` (use the `copy()` method).  You will use data cleaning methods to update `clean_data`.\n\n2. Remove any duplicate rows from the DataFrame\n   - Print it and run the tests.\n\n3. Convert `Age` to numeric and handle missing values\n   - Print it and run the tests.\n\n4. Convert `Salary` to numeric and replace known placeholders (`unknown`, `n/a`) with NaN\n   - print it and run the tests.\n\n5. Fill missing numeric values (use `fillna`).  Fill `Age` which the mean and `Salary` with the median\n   - Print it and run the tests\n\n6. Convert `Hire Date` to `datetime`\n   - Print it and run the tests\n\n7. Strip extra whitespace and standardize `Name` and `Department` as uppercase\n   - Print it and run the tests\n\n\n---\n\n### **Step 2: Submit Your Assignment on GitHub**  \n\n**Follow these steps to submit your work:**  \n\n#### **1️⃣ Add, Commit, and Push Your Changes**  \n- Within your python_homework folder, do a git add and a git commit for the files you have created, so that they are added to the `assignment4` branch.\n- Push that branch to GitHub. \n\n#### **2️⃣ Create a Pull Request**  \n- Log on to your GitHub account.\n- Open your `python_homework` repository.\n- Select your `assignment4` branch.  It should be one or several commits ahead of your main branch.\n- Create a pull request.\n\n#### **3️⃣ Submit Your GitHub Link**  \n- Your browser now has the link to your pull request.  Copy that link. \n- Paste the URL into the **assignment submission form**.  \n\n---\n",
        "codeExample": "",
        "_id": "68796c78a4ac7ef2a17a617e"
      }
    ],
    "submissionInstructions": "Please submit on time",
    "checklist": [],
    "checkForUnderstanding": []
  },
  "subsections": [
    {
      "subsectionOrder": 1,
      "title": "Lesson 4",
      "content": "# Lesson 4 — Intro to Data Engineering\n\n## Lesson Overview\n\n**Learning objective:** Students will learn to load, preview, and inspect datasets in Pandas by reading data from common formats and summarizing data structure to facilitate efficient data analysis.\n\nTopics:\n\n  * Introduction to Pandas: Creating and manipulating DataFrames.\n  * Loading Data: Reading data from CSV, JSON, and dictionaries.\n  * Data Inspection: Using head(), tail(), info() to inspect datasets.\n\n## 3.1 Intro to Pandas\n\n**Pandas** is a very powerful, open-source library for data analysis and manipulation in Python. It's widely used for handling and analyzing data structures, particularly in tabular format. With Pandas, you can work easily with structured data, perform data cleaning, and conduct complex transformations.  You can read more about pandas [here](https://pandas.pydata.org/docs/index.html).\n\n### Why Use Pandas? \nPandas provides data structures like **DataFrames** and **Series** that make data manipulation in Python simpler and faster. It's well-suited for tasks that involve:\n\n  * Loading data from different file formats (CSV, Excel, SQL, etc.)\n  * Cleaning and transforming messy data\n  * Summarizing data for analysis\n  * Visualizing data with integration to other libraries like Matplotlib and Seaborn\n\n### Getting Started with Pandas\nTypically, to get started, you would do the following.\n\n```bash\npip install pandas\n```\n\n**But this is not necessary when you use your python_homework repository.** When you set up the folder, you installed all of the packages in `requirements.txt`, and that included Pandas.\n\nOnce the package is installed, you can import it in your Python code: \n\n```python\nimport pandas as pd\n```\n\n### The numpy library ###\n\nThe numpy library provides highly optimized datatypes and numerical operations for python.  It is written in c and compiled to binary code which is linked with python.  Numerical computation in python using numpy are competitive with compiled languages like c++ and much faster than native python.  The pandas library is built on top of numpy and numpy numbers are often used with pandas.  You can read more about numpy [here](https://numpy.org/).\n\n### Key Data Structures\n\n1. **Series**: A one-dimensional array-like structure, similar to a list or array, but with added features such as **customizable indexes**. Each element in a Series is associated with a label (the index), allowing for more intuitive data manipulation and access.\n2. **Data Frame:** A two-dimensional table where each column can hold different types of data. This is the most commonly used data structure in Pandas.\n\n#### Example: Creating a Series\n\n**You should run all of the following code examples within the Python interactive shell.**  Start VSCode from within your `python_homework` directory, start a terminal within VSCode, and enter the `python` command to start it. Then run the following code:\n\n```python\n# Creating a simple Series\nimport pandas as pd\n\ndata = [1, 3, 5, 7, 9]\ns = pd.Series(data, name=\"numbers\")\nprint(s)\n```\n\nThe output should be: \n\n```yaml\n0    1\n1    3\n2    5\n3    7\n4    9\nName: numbers, dtype: int64\n```\n\nA Series is a one dimensional data structure.  The column on the left is the index.  The column on the right is the data.\n\n#### Key Features of a Series:\n1. **Customizable Indexes**:\n   - Unlike standard lists or arrays, a Series can have user-defined labels for its indices, making it easier to differentiate and access data.\n   - For example:\n     ```python\n     import pandas as pd # The import only needs to be done once per interactive session\n     data = pd.Series([10, 20, 30], index=[\"a\", \"b\", \"c\"])\n     print(data)\n     # Output:\n     # a    10\n     # b    20\n     # c    30\n     ```\n   - To give a more difficult case, do this one:\n     ```python\n     data2 = pd.Series(['Tom', 'Li', 'Antonio', 'Mary'], index=[5, 2, 2, 3])\n     print(data2)\n     # Output:\n     # 5 Tom\n     # 2 Li\n     # 2 Antonio\n     # 3 Mary\n     print(data2[2])\n     # Output:\n     # 2 Li\n     # 2 Antonio\n     print(data2[1])\n     # This gives a key error!\n     ```\n    - **Notice the following:** Index labels are not necessarily numbers, nor are they in sequential order, and they may not even be unique.  They are **not** the same as the row number.  If some index label is not unique, and you request the value of the series for that index label, what is returned is another series.  This is called `levels` in Pandas.  Try the following:\n     ```python\n     data3 = data2.reset_index()\n     print(data3)\n     # output:\n     # 0 Tom\n     # 1 Li\n     # 2 Antonio\n     # 3 Mary\n     ```\n   - The order of entries in the Series does not change.  In Pandas, Series are value-mutable, meaning that you can change the value stored at a particular location, but are not size or order mutable.  Also, the index labels in a Series are immutable.\n2. Access entries by index label or position\n#### Example: Differentiating a Series from a List\n```python\n# List Example\nmy_list = [10, 20, 30]\nprint(my_list[1])  # Access by position\n# Output: 20\n\n# Series Example\nmy_series = pd.Series([10, 20, 30], index=[\"a\", \"b\", \"c\"])\nprint(my_series[\"b\"])  # Access by index label\n# Output: 20\n\nprint(my_series.iloc[2]) # Access by integer position\n# Output: 30\n```\n\n3. **Operations on an entire series:**\n```python\nmy_revised_series = my_series * 2\nprint(my_revised_series)\n# Output:\na 20\nb 40\nc 60\n```\nThis does not work for lists!  As we will see, there are other ways to change a series, including a map() method and numpy functions.\n\n#### Example: Creating a DataFrame\nDataFrames are like tables in a database or spreadsheet. To create a DataFrame from a dict, run the following code in Python: \n\n```python\n# Creating a DataFrame from a dict\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [24, 27, 22],\n    'City': ['New York', 'San Francisco', 'Chicago']\n}\ndf = pd.DataFrame(data)\nprint(df)\n```\n\nThe output should be: \n\n```markdown\n      Name  Age           City\n0    Alice   24       New York\n1      Bob   27  San Francisco\n2  Charlie   22        Chicago\n```\n\nOne can also create a dataframe from a list of dicts:\n\n```python\ndata_alice = {'Name': 'Alice', 'Age': 24, 'City': 'New York'}\ndata_bob = {'Name': 'Bob', 'Age': 27, 'City': 'San Francisco'}\ndata_charlie = {'Name': 'Charlie', 'Age': 22, 'City': 'Chicago'}\ndf = pd.DataFrame([data_alice, data_bob, data_charlie])\nprint(df)\n# output: same as before\n```\n\n#### Loading data from numpy objects\nIn addition to initialization from python Lists and Dictionaries demonstrated in the examples above, Pandas can be initialized from numpy objects.\n\n```python\nimport numpy as np # load the numpy library\n# Create a Pandas DataFrame using NumPy arrays\ndata = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\ndf = pd.DataFrame(data, columns=['A', 'B', 'C'])\n\nprint(df)\n\n```\n\n#### the DataFrame index and column labels\nDataFrames include an index.  The index provides a label for each row.  Again, this is **not** the same as the row number.  It can be useful for operations such as indexing, data alignment and subsetting.  For some of the operations we will discuss, we add an optional parameter to ignore the index since there is additional complexity involved in setting it up correctly.  For example, the index would need to be reset when combining two DataFrames.  DataFrames also have column labels.  These are typically descriptive strings.  You *can* have non-distinct column labels, but this is usually not helpful.\n\n\n### Common Operations in Pandas\n\n#### Reading Data\nPandas makes it easy to read data from files. For instance, to read data from a CSV file: \n\n```python\n# Read data from a CSV file\ndf = pd.read_csv('data.csv')\n```\n\n#### Combining two DataFrames\nThe `concat` method can be used to combine two DataFrames.\n\n```python\ndata = pd.DataFrame({\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [24, 27, 22],\n    'City': ['New York', 'San Francisco', 'Chicago']\n})\n\nmore_data = pd.DataFrame({\n  'Name': ['Fred', 'Barney'],\n  'Age': [57, 55],\n  'City': ['Bedrock', 'Bedrock']\n})\n\ndf = pd.concat([data, more_data], ignore_index=True)\n```\n\n#### Data Selection\nYou can select entries, rows and columns from a DataFrame in various ways. \n```python\n# Select an entry by index label and column\nprint(df.loc[1,'Name'])\n# Output: Bob\n\n# Select an entry by position\nprint(df.iloc[1, 1])\n# Output: 27\n```\n\nIn either case, **you specify the row first, and then the column.**\n\n```python\n# Select a single column\nprint(df['Age'])\n\n# Select multiple columns\nprint(df[['Name', 'City']])\n\n```\nWhen you select columns in this way, you obtain views or references to one or more columns in the DataFrame.\n- Each reference points to a Series.  Each Series has the same index labels as the DataFrame itself.\n- You should regard these views as read/only.  If you try to change the values in one of these series, you might get a warning, and it might not change the value in the original DataFrame.\n- The following is a bad practice:\n  ```python\n  df['Age'][1] = 35\n  ```\n  This changes the value in a view, which is a bad idea.  There are two correct ways to do this.\n  ```python\n  age_series = df['Age'].copy() # creates a new series\n  age_series[1] = 35 # changes the value in the series\n  df['Age'] = age_series # replaces the previous column with the new series\n  ```\n  This approach is long-winded if you are only changing one entry in a column.  More direct is:\n  ```python\n  df.loc[1,'Age'] = 35\n  ```\n\n```python\n# Select rows by index position\nprint(df.iloc[1])  # Select the second row\n\n# Select rows by condition\nprint(df[df['Age'] > 23])\n```\nWhen you select rows in this way, you get one or more Series.  These are copies of the data from the DataFrame.  If you change the values in these Series, that does not affect the original DataFrame.  The index labels for these series are the column labels from the original DataFrame.\n\nThe size, row order, and index labels for a Pandas DataFrame are immutable.  The values and column labels are mutable, and entire columns can be added, removed, or replaced.\n\n### Data Aggregation\nPandas also allows for powerful aggregations, such as finding the mean or sum of a column. \n\n```python\n# Find the average age\nprint(df['Age'].mean())\n\n# Count the number of unique cities\nprint(df['City'].nunique())\n```\n\n### Data Cleaning\nHandling missing data and cleaning data is essential in data analysis.  These are some examples of the data cleaning methods which are available. We will cover data cleaning in more detail in future lessons.\n\n#### Converting Columns to Numeric\n\n```python\nimport pandas as pd\n\ndata = {\n    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"Height\": [\"5.5\", \"unknown\", \"5.9\"],  # \"unknown\" is not numeric\n    \"Weight\": [\"60\", \"70\", \"NaN\"]        # \"NaN\" is a missing placeholder\n}\ndf = pd.DataFrame(data)\n\nprint(\"Before conversion:\")\nprint(df)\n\n# Replace placeholders with NaN and convert to numeric\ndf[\"Height\"] = df[\"Height\"].replace(\"unknown\", pd.NA)\ndf[\"Height\"] = pd.to_numeric(df[\"Height\"], errors=\"coerce\")\ndf[\"Weight\"] = pd.to_numeric(df[\"Weight\"], errors=\"coerce\")\n\nprint(\"\\nAfter conversion to numeric:\")\nprint(df)\n\n \n```\n\n#### Handling Missing Values with `fillna()`\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    \"Person\": [\"Alice\", \"Bob\", \"Charlie\", \"Dana\", \"Eve\"],\n    \"Score\": [10, np.nan, 20, None, 25],\n    \"City\": [\"New York\", \"Chicago\", None, \"Boston\", \"NaN\"]\n}\ndf = pd.DataFrame(data)\n\nprint(\"Original DataFrame:\")\nprint(df)\n\n# Strategy 1: Fill numeric missing values with a fixed number\ndf[\"Score_filled_fixed\"] = df[\"Score\"].fillna(0)\n\n# Strategy 2: Fill numeric missing values with the column mean\nmean_score = df[\"Score\"].mean()  # ignoring NaNs\ndf[\"Score_filled_mean\"] = df[\"Score\"].fillna(mean_score)\n\n# Strategy 3: Fill textual missing values with \"Unknown\"\ndf[\"City_filled\"] = df[\"City\"].replace(\"NaN\", pd.NA).fillna(\"Unknown\")\n\nprint(\"\\nDataFrame after fillna strategies:\")\nprint(df)\n\n\n```\n\n#### Forward fill and backward fill\n\nHandle missing data in a time series or sequential data scenario.\n\n```python\nimport pandas as pd\nimport numpy as np\n\ndata = {\n    \"Day\": [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"],\n    \"Sales\": [100, np.nan, 150, np.nan, 200]\n}\ndf = pd.DataFrame(data)\n\nprint(\"Original Sales Data:\")\nprint(df)\n\n# Forward fill (propagate last valid observation forward)\ndf_ffill = df.copy()\ndf_ffill[\"Sales\"] = df_ffill[\"Sales\"].fillna(method=\"ffill\")\n\n# Backward fill (use next valid observation to fill gaps)\ndf_bfill = df.copy()\ndf_bfill[\"Sales\"] = df_bfill[\"Sales\"].fillna(method=\"bfill\")\n\nprint(\"\\nForward Fill Result:\")\nprint(df_ffill)\n\nprint(\"\\nBackward Fill Result:\")\nprint(df_bfill)\n\n\n```\n\n#### Text Standardization (strip, upper, lower)\n\n```python\nimport pandas as pd\n\ndata = {\n    \"Department\": [\" SALES \", \"   HR\", \"FinanCe  \", \"Sales\", \"MARKETING \"],\n    \"Location\": [\" New York \", \" Boston\", \"Chicago   \", \"  Boston \", \"LOS ANGELES\"]\n}\ndf = pd.DataFrame(data)\n\nprint(\"Original DataFrame:\")\nprint(df)\n\n# Strip whitespace\ndf[\"Department\"] = df[\"Department\"].str.strip()\ndf[\"Location\"] = df[\"Location\"].str.strip()\n\n# Convert columns to uppercase\ndf[\"Department_upper\"] = df[\"Department\"].str.upper()\ndf[\"Location_upper\"] = df[\"Location\"].str.upper()\n\n# Or lowercase, if you prefer\ndf[\"Department_lower\"] = df[\"Department\"].str.lower()\n\nprint(\"\\nAfter text standardization:\")\nprint(df)\n\n\n```\n\n#### Converting dates to `datetime`\n\n```python\nimport pandas as pd\n\n# Sample data with dates in various formats and some invalid values\ndata = {\n    \"Event\": [\"Project Start\", \"Client Meeting\", \"Beta Release\", \"Final Launch\"],\n    \"Date\": [\"2021/01/15\", \"2021-02-30\", \"03-15-2021\", \"April 31, 2021\"]  # Some invalid or unusual dates\n}\ndf = pd.DataFrame(data)\n\nprint(\"Before conversion:\")\nprint(df)\n\n# Convert 'Date' to datetime\n# errors=\"coerce\" will turn invalid dates into NaT (Not a Time)\ndf[\"Date_converted\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n\nprint(\"\\nAfter converting to datetime:\")\nprint(df)\n\n# You can check how many values became NaT (invalid dates)\nnum_invalid_dates = df[\"Date_converted\"].isna().sum()\nprint(f\"\\nNumber of invalid dates converted to NaT: {num_invalid_dates}\")\n\n\n```\n\n### Saving DataFrames to CSV Files\n\nPandas makes it easy to save DataFrames as CSV files, which is useful for sharing, storing, or exporting data for later use. You can use the to_csv() method to save your DataFrame to a CSV file\n```python\nDataFrame.to_csv(filepath, sep=',', index=True, header=True, encoding=None)\n```\n```filepath```: The name or path of the CSV file to save (e.g., ```\"output.csv\"```)   \n```sep```: The delimiter to use (default is a comma ```,```).   \n```index```: Whether to include the index as a column in the file (default is ```True```).   \n```header```: Whether to include column names as the first row (default is ```True```).\n\n\n### Save a DataFrame to a CSV File\n```python\nimport pandas as pd\n\n# Create a sample DataFrame\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [26, 31, 36],\n    'City': ['New York', 'Los Angeles', 'Chicago'],\n    'Salary': [70000, 80000, 90000]\n}\ndf = pd.DataFrame(data)\n\n# Save the DataFrame to a CSV file\ndf.to_csv(\"employees.csv\", index=False)\n\nprint(\"DataFrame saved to employees.csv\")\n```\nOutput File (employees.csv):\n\n```sql\nName,Age,City,Salary\nAlice,26,New York,70000\nBob,31,Los Angeles,80000\nCharlie,36,Chicago,90000\n\n```\n### 3.1 Videos: Installing and Using Pandas\n\nIn these two videos, we'll walk through installing and using Pandas in Python. This is an important step! If you're still feeling confused, contact a 1:1 mentor to walk through Pandas.\n\n**[Video: What is Pandas? Why and How to Use in Python](https://youtu.be/dcqPhpY7tWk?feature=shared).**\n\n*Note: The above video demonstrates using Pandas with Jupytr notebook. If you would like a look at using Pandas in VS Code, take time to look at the video below as well.*\n\n**[Video: Installing Pandas in VSCode](https://youtu.be/4WZK0eovQIA?feature=shared).**\n\n### 3.1 Check for Understanding\n\n1. Which data structure is used for storing a two-dimensional table in Pandas?\n  * A) List\n  * B) Array\n  * C) DataFrame\n  * D) Series\n\n<details>\n\n<summary>Answer</summary>\n1. C) DataFrame\n</details>\n\n\n2. How can you select rows in a DataFrame where a specific column value is greater than 10?\n  * A) `df.loc[df['column'] > 10]`\n  * B) `df.loc[df['column'] < 10]`\n  * C) `df['column'] > 10`\n  * D) `df.loc(column > 10)`\n  \n<details>\n\n<summary>Answer</summary>\n2. A) `df.loc[df['column'] > 10]`\n\n</details>\n\nGreat work! With these basics, you can now start using Pandas for various data manipulation and analysis tasks.\n\n## 3.2 Loading Data in Pandas\n\nPandas provides convenient methods for loading data from various sources, such as CSV and JSON files, as well as Python dictionaries. This makes it easy to get your data into a format where you can start analyzing it.\n\n### Reading Data from a CSV File\n\nAs you recall from Lesson 2, **CSV** (Comma-Separated Values) is one of the most common data formats, especially for tabular data. Pandas makes it simple to read and manipulate CSV files.\n\n#### Example: Reading a CSV File\n\nTo load a CSV file, use `pd.read_csv()`.\n\n```python\nimport pandas as pd\n\n# Load the data from a CSV file\ndf = pd.read_csv('data.csv')\nprint(df.head())\n```\n\nHere, `df.head()` will display the first five rows of the DataFrame by default. You can also customize `pd.read_csv()` with various parameters:\n\n```python\n# Loading a CSV file with custom parameters\ndf = pd.read_csv('data.csv', delimiter=';', header=0, index_col='ID')\n```\n\nIn the above example,\n  * `delimiter` defines a custom separator (e.g., `;`)\n  * `header` indicates the row for column headers (defaults to the first row)\n  * `index_col` sets a column to be used as the DataFrame index.\n\n### Reading Data from a JSON File\n\n**JSON** (JavaScript Object Notation) is another popular format, often used for data exchange on the web. Pandas can read JSON files directly into a DataFrame.\n\n#### Example: Reading a JSON File\n\nTo load a JSON file, use `pd.read_json()`. Note that this function looks the same as the one we used for a CSV file, we've just replaced `csv` with `json`.\n\n```python\n# Load the data from a JSON file\ndf = pd.read_json('data.json')\nprint(df.head())\n```\n\nThe JSON structure should be either a list of dictionaries (each representing a row) or a dictionary of lists (each representing a column). Here’s two examples of JSON data that can be read into a DataFrame:\n\n```json\n[\n    {\"Name\": \"Alice\", \"Age\": 24, \"City\": \"New York\"},\n    {\"Name\": \"Bob\", \"Age\": 27, \"City\": \"San Francisco\"},\n    {\"Name\": \"Charlie\", \"Age\": 22, \"City\": \"Chicago\"}\n]\n```\n\nThe same DataFrame can be read using this JSON structure.  It's a bit simpler since it doesn't repeat the column names.\n\n```json\n{ \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n  \"Age\": [25, 30, 35],\n  \"City\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n}\n```\n\nFor complex JSON structures, you may need to specify additional parameters, or preprocess the JSON data before loading.\n\n\n\n### Using the `sep` Parameter in Pandas\n\nIn **Pandas**, the `sep` parameter is commonly used when reading or writing CSV (or similar) files. It specifies the **delimiter** (separator) used in the file to distinguish between columns.\n\n\n### Common Methods with `sep`\n\n1. **`pd.read_csv()`**: Reads a file and uses the `sep` parameter to define how columns are separated.\n\n2. **`DataFrame.to_csv()`**: Exports a DataFrame and uses `sep` to specify the delimiter in the output file.\n\n\n### Example 1: Reading a CSV File with a Custom Separator\n\nSome CSV files may use delimiters other than a comma, such as tabs (`\\t`) or pipes (`|`).\n\n```python\nimport pandas as pd\n\n# Read a CSV file with pipe as the separator\ndata = pd.read_csv(\"data.csv\", sep=\"|\")\nprint(data.head())\n```\n\nIf the file contains:\n\n```sql\nName|Age|City\nAlice|30|New York\nBob|25|Los Angeles\n```\n\nThe output will be:\n\n```markdown\n    Name  Age         City\n0  Alice   30     New York\n1    Bob   25  Los Angeles\n```\n\n### Example 2: Writing a CSV File with a Custom Separator\n\nYou can export a DataFrame using a custom delimiter instead of the default comma.\n\n```python\n# Create a sample DataFrame\ndf = pd.DataFrame({\n    \"Name\": [\"Alice\", \"Bob\"],\n    \"Age\": [30, 25],\n    \"City\": [\"New York\", \"Los Angeles\"]\n})\n\n# Save the DataFrame to a CSV file with a tab as the separator\ndf.to_csv(\"output.tsv\", sep=\"\\t\", index=False)\n```\n\nThe output file `output.tsv` will look like this:\n\n```sql\nName\tAge\tCity\nAlice\t30\tNew York\nBob\t25\tLos Angeles\n```\n\n#### Why Use `sep`?\n\n* **Flexibility:** Handle files with different delimiters (e.g., tabs, pipes, semicolons).\n* **Compatibility:** Work with non-standard or region-specific CSV formats.\n\n#### Loading Data from a Dictionary\n\nPandas also allows you to create DataFrames from Python dictionaries directly, which is useful when you already have data in a Python program.\n\n#### Example: Loading Data from a Dictionary\n\nIf you have a dictionary where keys represent column names and values represent the data, you can use `pd.DataFrame()` to create a DataFrame.\n\n```python\n# Create a dictionary\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [24, 27, 22],\n    'City': ['New York', 'San Francisco', 'Chicago']\n}\n\n# Convert the dictionary to a DataFrame\ndf = pd.DataFrame(data)\nprint(df)\n```\n\nThis will output: \n\n```markdown\n      Name  Age           City\n0    Alice   24       New York\n1      Bob   27  San Francisco\n2  Charlie   22        Chicago\n```\n\n### Summary of Methods\n\n| Format     | Method           | Example                          |\n|------------|-------------------|----------------------------------|\n| CSV        | `pd.read_csv()`   | `df = pd.read_csv('data.csv')`   |\n| JSON       | `pd.read_json()`  | `df = pd.read_json('data.json')` |\n| Dictionary | `pd.DataFrame()`  | `df = pd.DataFrame(data)`        |\n\n### 3.2 Check for Understanding\n\n1. Which function is used to load data from a JSON file into a DataFrame?\n\n  * A) pd.read_csv()\n  * B) pd.read_json()\n  * C) pd.DataFrame()\n  * D) pd.read_dict()\n<details>\n\n<summary>Answer</summary>\n1. B) `pd.read_json()`\n</details>\n\n2. If your CSV file uses semicolons (;) instead of commas, which parameter can you use to specify this in pd.read_csv()?\n\n  * A) separator\n  * B) delimiter\n  * C) sep\n  * D) Both b and c\n\n<details>\n\n<summary>Answer</summary>\n\n2. D) Both B and C\n\n</details>\n\nWith these functions, you’re equipped to load data from different formats into Pandas, ready for analysis!\n\n## 3.3 Data Inspection\n\nOnce you've loaded data into a DataFrame, it’s essential to inspect it to understand its structure, spot any missing values, and identify the data types of each column. Pandas provides several convenient methods for quickly viewing and summarizing your dataset.\n\n### Using `head()` and `tail()` to Preview Data\n\nThe `head()` and `tail()` methods allow you to preview the first or last few rows of your DataFrame. By default, they show 5 rows, but you can specify any number you want.\n\n#### Example: Using `head()`\n\n`head()` is typically used to get a quick look at the beginning of the dataset.\n\n```python\nimport pandas as pd\n\n# Load some sample data\ndf = pd.DataFrame({\n    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n    'Age': [24, 27, 22, 32, 29, 41],\n    'City': ['New York', 'San Francisco', 'Chicago', 'Los Angeles', 'Houston', 'Seattle']\n})\n\n# Display the first 3 rows\nprint(df.head(3))\n```\n\nThis will output: \n\n```markdown\n      Name  Age           City\n0    Alice   24       New York\n1      Bob   27  San Francisco\n2  Charlie   22        Chicago\n```\n\n#### Example: Using `tail()`\n\nSimilarly, `tail()` allows you to view the last few rows of the DataFrame.\n\n```python\n# Display the last 2 rows\nprint(df.tail(2))\n```\n\nThis will output: \n\n```\n    Name  Age     City\n4    Eve   29   Houston\n5  Frank   41   Seattle\n```\n\n### Using `info()` to Get a Summary of the DataFrame\n\nThe `info()` method provides a summary of the DataFrame, including: \n  * The number of entries (rows)\n  * The data types of each column\n  * The number of non-null (non-missing) values in each column\n  * Memory usage of the DataFrame\n\n\n#### Example: Using `info()`\n\n```python\n# Get a summary of the DataFrame\ndf.info()\n```\nThis will output: \n\n```python\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6 entries, 0 to 5\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   Name    6 non-null      object\n 1   Age     6 non-null      int64 \n 2   City    6 non-null      object\ndtypes: int64(1), object(2)\nmemory usage: 272.0 bytes\n```\n\nFrom this output, you can see the column names, data types, number of non-null entries per column, and how much memory the DataFrame consumes. This summary is helpful for understanding the dataset's overall structure.\n\n### Summary of Methods\n\n| Format     | Description           | \n|------------|-------------------|\n| `head()`        | Displays the first few rows of the DataFrame  | \n| `tail()`       | Displays the last five rows of the DataFrame  | \n| `info()` | Summarizes the DataFrame, including data types, null counts, and memory usage  | \n\n### 3.3 Check for Understanding\n\n1. What is the default number of rows displayed when using `df.head()`?\n\n     * A) 3\n     * B) 5\n     * C) 7\n     * D) 10\n <details>\n\n<summary>Answer</summary> \n1. B) 5\n</details>\n  \n2. Which method provides information about column data types and memory usage?\n\n     * A) `head()`\n     * B) `tail()`\n     * C) `summary()`\n     * D) `info()`\n\n<details>\n\n<summary>Answer</summary> \n\n2. D) `info()`\n\n</details>\n\n---\nThis content was written by Janet Zulu, Reid Russom, and CTD volunteers—with special thanks to the brain trust of John McGarvey, Rebecca Callari-Kaczmarczyk, Tom Arns, and Josh Sternfeld. To submit feedback, please fill out the **[CTD Curriculum Feedback Form](https://forms.gle/RZq5mav7wotFxyie6)**.\n",
      "videoUrl": "",
      "codeExamples": [],
      "externalLinks": [],
      "quizzes": [],
      "_id": "68796c78a4ac7ef2a17a617d"
    }
  ]
}